import {
  PG_ADMIN_SHUTDOWN,
  PG_OBJECT_IN_USE,
} from '@drdgvhbh/postgres-error-codes';
import {LogContext} from '@rocicorp/logger';
import postgres from 'postgres';
import {AbortError} from '../../../../../shared/src/abort-error.ts';
import {deepEqual} from '../../../../../shared/src/json.ts';
import {must} from '../../../../../shared/src/must.ts';
import {promiseVoid} from '../../../../../shared/src/resolved-promises.ts';
import {
  equals,
  intersection,
  symmetricDifferences,
} from '../../../../../shared/src/set-utils.ts';
import {sleep} from '../../../../../shared/src/sleep.ts';
import * as v from '../../../../../shared/src/valita.ts';
import {Database} from '../../../../../zqlite/src/db.ts';
import {mapPostgresToLiteColumn} from '../../../db/pg-to-lite.ts';
import {ShortLivedClient} from '../../../db/short-lived-client.ts';
import type {
  ColumnSpec,
  PublishedTableSpec,
  TableSpec,
} from '../../../db/specs.ts';
import {StatementRunner} from '../../../db/statements.ts';
import {stringify} from '../../../types/bigint-json.ts';
import {
  oneAfter,
  versionFromLexi,
  versionToLexi,
  type LexiVersion,
} from '../../../types/lexi-version.ts';
import {pgClient, type PostgresDB} from '../../../types/pg.ts';
import {
  upstreamSchema,
  type ShardConfig,
  type ShardID,
} from '../../../types/shards.ts';
import type {Sink} from '../../../types/streams.ts';
import {Subscription, type PendingResult} from '../../../types/subscription.ts';
import type {
  ChangeSource,
  ChangeStream,
} from '../../change-streamer/change-streamer-service.ts';
import {AutoResetSignal} from '../../change-streamer/schema/tables.ts';
import {
  getSubscriptionState,
  type SubscriptionState,
} from '../../replicator/schema/replication-state.ts';
import type {
  DataChange,
  Identifier,
  MessageDelete,
} from '../protocol/current/data.ts';
import type {
  ChangeStreamData,
  ChangeStreamMessage,
  Data,
} from '../protocol/current/downstream.ts';
import {type InitialSyncOptions} from './initial-sync.ts';
import type {
  Message,
  MessageMessage,
  MessageRelation,
} from './logical-replication/pgoutput.types.ts';
import {subscribe} from './logical-replication/stream.ts';
import {fromBigInt, toLexiVersion, type LSN} from './lsn.ts';
import {replicationEventSchema, type DdlUpdateEvent} from './schema/ddl.ts';
import {updateShardSchema} from './schema/init.ts';
import {getPublicationInfo, type PublishedSchema} from './schema/published.ts';
import {
  getInternalShardConfig,
  getReplicaAtVersion,
  internalPublicationPrefix,
  legacyReplicationSlot,
  replicaIdentitiesForTablesWithoutPrimaryKeys,
  replicationSlotExpression,
  type InternalShardConfig,
  type Replica,
} from './schema/shard.ts';
import {validate} from './schema/validation.ts';
import {initSyncSchema} from './sync-schema.ts';

/**
 * Initializes a Postgres change source, including the initial sync of the
 * replica, before streaming changes from the corresponding logical replication
 * stream.
 */
export async function initializePostgresChangeSource(
  lc: LogContext,
  upstreamURI: string,
  shard: ShardConfig,
  replicaDbFile: string,
  syncOptions: InitialSyncOptions,
): Promise<{subscriptionState: SubscriptionState; changeSource: ChangeSource}> {
  await initSyncSchema(
    lc,
    `replica-${shard.appID}-${shard.shardNum}`,
    shard,
    replicaDbFile,
    upstreamURI,
    syncOptions,
  );

  const replica = new Database(lc, replicaDbFile);
  const subscriptionState = getSubscriptionState(new StatementRunner(replica));
  replica.close();

  if (shard.publications.length) {
    // Verify that the publications match what has been synced.
    const requested = [...shard.publications].sort();
    const replicated = subscriptionState.publications
      .filter(p => !p.startsWith(internalPublicationPrefix(shard)))
      .sort();
    if (!deepEqual(requested, replicated)) {
      throw new Error(
        `Invalid ShardConfig. Requested publications [${requested}] do not match synced publications: [${replicated}]`,
      );
    }
  }

  // Check that upstream is properly setup, and throw an AutoReset to re-run
  // initial sync if not.
  const db = pgClient(lc, upstreamURI);
  try {
    const upstreamReplica = await checkAndUpdateUpstream(
      lc,
      db,
      shard,
      subscriptionState.replicaVersion,
    );

    const changeSource = new PostgresChangeSource(
      lc,
      upstreamURI,
      shard,
      upstreamReplica,
    );

    return {subscriptionState, changeSource};
  } finally {
    await db.end();
  }
}

async function checkAndUpdateUpstream(
  lc: LogContext,
  db: PostgresDB,
  shard: ShardConfig,
  replicaVersion: string,
) {
  // Perform any shard schema updates
  await updateShardSchema(lc, db, shard, replicaVersion);

  const upstreamReplica = await getReplicaAtVersion(db, shard, replicaVersion);
  if (!upstreamReplica) {
    throw new AutoResetSignal(
      `No replication slot for replica at version ${replicaVersion}`,
    );
  }
  const {slot} = upstreamReplica;
  const result = await db<{restartLSN: LSN | null}[]>`
  SELECT restart_lsn as "restartLSN" FROM pg_replication_slots WHERE slot_name = ${slot}`;
  if (result.length === 0) {
    throw new AutoResetSignal(`replication slot ${slot} is missing`);
  }
  const [{restartLSN}] = result;
  if (restartLSN === null) {
    throw new AutoResetSignal(
      `replication slot ${slot} has been invalidated for exceeding the max_slot_wal_keep_size`,
    );
  }
  return upstreamReplica;
}

/**
 * Postgres implementation of a {@link ChangeSource} backed by a logical
 * replication stream.
 */
class PostgresChangeSource implements ChangeSource {
  readonly #lc: LogContext;
  readonly #upstreamUri: string;
  readonly #shard: ShardID;
  readonly #replica: Replica;

  constructor(
    lc: LogContext,
    upstreamUri: string,
    shard: ShardID,
    replica: Replica,
  ) {
    this.#lc = lc.withContext('component', 'change-source');
    this.#upstreamUri = upstreamUri;
    this.#shard = shard;
    this.#replica = replica;
  }

  async startStream(clientWatermark: string): Promise<ChangeStream> {
    const db = pgClient(this.#lc, this.#upstreamUri);
    const {slot} = this.#replica;

    let cleanup = promiseVoid;
    try {
      ({cleanup} = await this.#stopExistingReplicationSlotSubscribers(
        db,
        slot,
      ));
      const config = await getInternalShardConfig(db, this.#shard);
      this.#lc.info?.(`starting replication stream@${slot}`);
      return await this.#startStream(db, slot, clientWatermark, config);
    } finally {
      void cleanup.then(() => db.end());
    }
  }

  async #startStream(
    db: PostgresDB,
    slot: string,
    clientWatermark: string,
    shardConfig: InternalShardConfig,
  ): Promise<ChangeStream> {
    const clientStart = oneAfter(clientWatermark);
    const {messages, acks} = await subscribe(
      this.#lc,
      db,
      slot,
      [...shardConfig.publications],
      versionFromLexi(clientStart),
    );

    const changes = Subscription.create<ChangeStreamMessage>({
      cleanup: () => messages.cancel(),
    });
    const acker = new Acker(acks);

    const changeMaker = new ChangeMaker(
      this.#lc,
      this.#shard,
      shardConfig,
      this.#replica.initialSchema,
      this.#upstreamUri,
    );

    void (async function () {
      try {
        for await (const [lsn, msg] of messages) {
          if (msg.tag === 'keepalive') {
            changes.push(['status', msg, {watermark: versionToLexi(lsn)}]);
            continue;
          }
          let last: PendingResult | undefined;
          for (const change of await changeMaker.makeChanges(lsn, msg)) {
            last = changes.push(change);
          }
          await last?.result; // Allow the change-streamer to push back.
        }
      } catch (e) {
        changes.fail(translateError(e));
      }
    })();

    this.#lc.info?.(
      `started replication stream@${slot} from ${clientWatermark} (replicaVersion: ${
        this.#replica.version
      })`,
    );

    return {
      changes,
      acks: {push: status => acker.ack(status[2].watermark)},
    };
  }

  /**
   * Stops all replication slots associated with this shard, and returns
   * a `cleanup` task that drops any slot other than the specified
   * `slotToKeep`.
   */
  async #stopExistingReplicationSlotSubscribers(
    db: PostgresDB,
    slotToKeep: string,
  ): Promise<{cleanup: Promise<void>}> {
    const slotExpression = replicationSlotExpression(this.#shard);
    const legacySlotName = legacyReplicationSlot(this.#shard);

    const result = await db<{slot: string; pid: string | null}[]>`
    SELECT slot_name as slot, pg_terminate_backend(active_pid), active_pid as pid
      FROM pg_replication_slots 
      WHERE slot_name LIKE ${slotExpression} OR slot_name = ${legacySlotName}`;
    if (result.length === 0) {
      // Note: This should not happen as it is checked at initialization time,
      //       but it is technically possible for the replication slot to be
      //       dropped (e.g. manually).
      throw new AbortError(
        `replication slot ${slotToKeep} is missing. Delete the replica and resync.`,
      );
    }
    // Clean up the replicas table.
    const replicasTable = `${upstreamSchema(this.#shard)}.replicas`;
    await db`DELETE FROM ${db(replicasTable)} WHERE slot != ${slotToKeep}`;

    const pids = result.filter(({pid}) => pid !== null).map(({pid}) => pid);
    if (pids.length) {
      this.#lc.info?.(`signaled subscriber ${pids} to shut down`);
    }
    const otherSlots = result
      .filter(({slot}) => slot !== slotToKeep)
      .map(({slot}) => slot);
    return {
      cleanup: otherSlots.length
        ? this.#dropReplicationSlots(db, otherSlots)
        : promiseVoid,
    };
  }

  async #dropReplicationSlots(db: PostgresDB, slots: string[]) {
    this.#lc.info?.(`dropping other replication slot(s) ${slots}`);
    for (let i = 0; i < 5; i++) {
      try {
        await db`
          SELECT pg_drop_replication_slot(slot_name) FROM pg_replication_slots
            WHERE slot_name IN ${db(slots)}
        `;
        this.#lc.info?.(`successfully dropped ${slots}`);
        return;
      } catch (e) {
        // error: replication slot "zero_slot_change_source_test_id" is active for PID 268
        if (
          e instanceof postgres.PostgresError &&
          e.code === PG_OBJECT_IN_USE
        ) {
          // The freeing up of the replication slot is not transactional;
          // sometimes it takes time for Postgres to consider the slot
          // inactive.
          this.#lc.debug?.(`attempt ${i + 1}: ${String(e)}`, e);
        } else {
          this.#lc.warn?.(`error dropping ${slots}`, e);
        }
        await sleep(1000);
      }
    }
    this.#lc.warn?.(`maximum attempts exceeded dropping ${slots}`);
  }
}

// Exported for testing.
export class Acker {
  #acks: Sink<bigint>;
  #keepaliveTimer: NodeJS.Timeout | undefined;

  constructor(acks: Sink<bigint>) {
    this.#acks = acks;
  }

  keepalive() {
    // Sets a timeout to send a standby status update in response to
    // a primary keepalive message.
    //
    // https://www.postgresql.org/docs/current/protocol-replication.html#PROTOCOL-REPLICATION-PRIMARY-KEEPALIVE-MESSAGE
    //
    // A primary keepalive message is streamed to the change-streamer as a
    // 'status' message, which in turn responds with an ack. However, in the
    // event that the change-streamer is backed up processing preceding
    // changes, this timeout will fire to send a status update that does not
    // change the confirmed flush position. This timeout must be shorter than
    // the `wal_sender_timeout`, which defaults to 60 seconds.
    //
    // https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-WAL-SENDER-TIMEOUT
    this.#keepaliveTimer ??= setTimeout(() => this.#sendAck(), 1000);
  }

  ack(watermark: LexiVersion) {
    this.#sendAck(watermark);
  }

  #sendAck(watermark?: LexiVersion) {
    clearTimeout(this.#keepaliveTimer);
    this.#keepaliveTimer = undefined;

    // Note: Sending '0/0' means "keep alive but do not update confirmed_flush_lsn"
    // https://github.com/postgres/postgres/blob/3edc67d337c2e498dad1cd200e460f7c63e512e6/src/backend/replication/walsender.c#L2457
    const lsn = watermark ? versionFromLexi(watermark) : 0n;
    this.#acks.push(lsn);
  }
}

type ReplicationError = {
  lsn: bigint;
  msg: Message;
  err: unknown;
  lastLogTime: number;
};

const SET_REPLICA_IDENTITY_DELAY_MS = 500;

class ChangeMaker {
  readonly #lc: LogContext;
  readonly #shardPrefix: string;
  readonly #shardConfig: InternalShardConfig;
  readonly #initialSchema: PublishedSchema;
  readonly #upstream: ShortLivedClient;

  #replicaIdentityTimer: NodeJS.Timeout | undefined;
  #error: ReplicationError | undefined;

  constructor(
    lc: LogContext,
    {appID, shardNum}: ShardID,
    shardConfig: InternalShardConfig,
    initialSchema: PublishedSchema,
    upstreamURI: string,
  ) {
    this.#lc = lc;
    // Note: This matches the prefix used in pg_logical_emit_message() in pg/schema/ddl.ts.
    this.#shardPrefix = `${appID}/${shardNum}`;
    this.#shardConfig = shardConfig;
    this.#initialSchema = initialSchema;
    this.#upstream = new ShortLivedClient(
      lc,
      upstreamURI,
      'zero-schema-change-detector',
    );
  }

  async makeChanges(lsn: bigint, msg: Message): Promise<ChangeStreamMessage[]> {
    if (this.#error) {
      this.#logError(this.#error);
      return [];
    }
    try {
      return await this.#makeChanges(msg);
    } catch (err) {
      this.#error = {lsn, msg, err, lastLogTime: 0};
      this.#logError(this.#error);
      // Rollback the current transaction to avoid dangling transactions in
      // downstream processors (i.e. changeLog, replicator).
      return [
        ['rollback', {tag: 'rollback'}],
        ['control', {tag: 'reset-required'}],
      ];
    }
  }

  #logError(error: ReplicationError) {
    const {lsn, msg, err, lastLogTime} = error;
    const now = Date.now();

    // Output an error to logs as replication messages continue to be dropped,
    // at most once a minute.
    if (now - lastLogTime > 60_000) {
      this.#lc.error?.(
        `Unable to continue replication from LSN ${fromBigInt(lsn)}: ${String(
          err,
        )}`,
        // 'content' can be a large byte Buffer. Exclude it from logging output.
        {...msg, content: undefined},
      );
      error.lastLogTime = now;
    }
  }

  // eslint-disable-next-line require-await
  async #makeChanges(msg: Message): Promise<ChangeStreamData[]> {
    switch (msg.tag) {
      case 'begin':
        return [
          ['begin', msg, {commitWatermark: toLexiVersion(must(msg.commitLsn))}],
        ];

      case 'delete': {
        if (!(msg.key ?? msg.old)) {
          throw new Error(
            `Invalid DELETE msg (missing key): ${stringify(msg)}`,
          );
        }
        // https://www.postgresql.org/docs/current/protocol-logicalrep-message-formats.html#PROTOCOL-LOGICALREP-MESSAGE-FORMATS-DELETE
        return [
          ['data', msg.old ? {...msg, key: msg.old} : (msg as MessageDelete)],
        ];
      }

      case 'update': {
        // https://www.postgresql.org/docs/current/protocol-logicalrep-message-formats.html#PROTOCOL-LOGICALREP-MESSAGE-FORMATS-UPDATE
        return [['data', msg.old ? {...msg, key: msg.old} : msg]];
      }

      case 'insert':
      case 'truncate':
        return [['data', msg]];

      case 'message':
        if (msg.prefix !== this.#shardPrefix) {
          this.#lc.debug?.('ignoring message for different shard', msg.prefix);
          return [];
        }
        return this.#handleCustomMessage(msg);

      case 'commit':
        return [
          ['commit', msg, {watermark: toLexiVersion(must(msg.commitLsn))}],
        ];

      case 'relation':
        return this.#handleRelation(msg);
      case 'type':
        return []; // Nothing need be done for custom types.
      case 'origin':
        // No need to detect replication loops since we are not a
        // PG replication source.
        return [];
      default:
        msg satisfies never;
        throw new Error(`Unexpected message type ${stringify(msg)}`);
    }
  }

  #preSchema: PublishedSchema | undefined;

  #handleCustomMessage(msg: MessageMessage) {
    const event = this.#parseReplicationEvent(msg.content);
    // Cancel manual schema adjustment timeouts when an upstream schema change
    // is about to happen, so as to avoid interfering / redundant work.
    clearTimeout(this.#replicaIdentityTimer);

    if (event.type === 'ddlStart') {
      // Store the schema in order to diff it with a potential ddlUpdate.
      this.#preSchema = event.schema;
      return [];
    }
    // ddlUpdate
    const changes = this.#makeSchemaChanges(
      must(this.#preSchema, `ddlUpdate received without a ddlStart`),
      event,
    ).map(change => ['data', change] satisfies Data);

    this.#lc
      .withContext('query', event.context.query)
      .info?.(`${changes.length} schema change(s)`, changes);

    const replicaIdentities = replicaIdentitiesForTablesWithoutPrimaryKeys(
      event.schema,
    );
    if (replicaIdentities) {
      this.#replicaIdentityTimer = setTimeout(async () => {
        try {
          await replicaIdentities.apply(this.#lc, this.#upstream.db);
        } catch (err) {
          this.#lc.warn?.(`error setting replica identities`, err);
        }
      }, SET_REPLICA_IDENTITY_DELAY_MS);
    }

    return changes;
  }

  /**
   *  A note on operation order:
   *
   * Postgres will drop related indexes when columns are dropped,
   * but SQLite will error instead (https://sqlite.org/forum/forumpost/2e62dba69f?t=c&hist).
   * The current workaround is to drop indexes first.
   *
   * Also note that although it should not be possible to both rename and
   * add/drop tables/columns in a single statement, the operations are
   * ordered to handle that possibility, by always dropping old entities,
   * then modifying kept entities, and then adding new entities.
   *
   * Thus, the order of replicating DDL updates is:
   * - drop indexes
   * - drop tables
   * - alter tables
   *   - drop columns
   *   - alter columns
   *   - add columns
   * - create tables
   * - create indexes
   *
   * In the future the replication logic should be improved to handle this
   * behavior in SQLite by dropping dependent indexes manually before dropping
   * columns. This, for example, would be needed to properly support changing
   * the type of a column that's indexed.
   */
  #makeSchemaChanges(
    preSchema: PublishedSchema,
    update: DdlUpdateEvent,
  ): DataChange[] {
    const [prevTbl, prevIdx] = specsByID(preSchema);
    const [nextTbl, nextIdx] = specsByID(update.schema);
    const changes: DataChange[] = [];

    // Validate the new table schemas
    for (const table of nextTbl.values()) {
      validate(this.#lc, table);
    }

    const [droppedIdx, createdIdx] = symmetricDifferences(prevIdx, nextIdx);
    for (const id of droppedIdx) {
      const {schema, name} = must(prevIdx.get(id));
      changes.push({tag: 'drop-index', id: {schema, name}});
    }

    // DROP
    const [droppedTbl, createdTbl] = symmetricDifferences(prevTbl, nextTbl);
    for (const id of droppedTbl) {
      const {schema, name} = must(prevTbl.get(id));
      changes.push({tag: 'drop-table', id: {schema, name}});
    }
    // ALTER
    const tables = intersection(prevTbl, nextTbl);
    for (const id of tables) {
      changes.push(
        ...this.#getTableChanges(must(prevTbl.get(id)), must(nextTbl.get(id))),
      );
    }
    // CREATE
    for (const id of createdTbl) {
      const spec = must(nextTbl.get(id));
      changes.push({tag: 'create-table', spec});
    }

    // Add indexes last since they may reference tables / columns that need
    // to be created first.
    for (const id of createdIdx) {
      const spec = must(nextIdx.get(id));
      changes.push({tag: 'create-index', spec});
    }
    return changes;
  }

  #getTableChanges(oldTable: TableSpec, newTable: TableSpec): DataChange[] {
    const changes: DataChange[] = [];
    if (
      oldTable.schema !== newTable.schema ||
      oldTable.name !== newTable.name
    ) {
      changes.push({
        tag: 'rename-table',
        old: {schema: oldTable.schema, name: oldTable.name},
        new: {schema: newTable.schema, name: newTable.name},
      });
    }
    const table = {schema: newTable.schema, name: newTable.name};
    const oldColumns = columnsByID(oldTable.columns);
    const newColumns = columnsByID(newTable.columns);

    // DROP
    const [dropped, added] = symmetricDifferences(oldColumns, newColumns);
    for (const id of dropped) {
      const {name: column} = must(oldColumns.get(id));
      changes.push({tag: 'drop-column', table, column});
    }

    // ALTER
    const both = intersection(oldColumns, newColumns);
    for (const id of both) {
      const {name: oldName, ...oldSpec} = must(oldColumns.get(id));
      const {name: newName, ...newSpec} = must(newColumns.get(id));
      // The three things that we care about are:
      // 1. name
      // 2. type
      // 3. not-null
      if (
        oldName !== newName ||
        oldSpec.dataType !== newSpec.dataType ||
        oldSpec.notNull !== newSpec.notNull
      ) {
        changes.push({
          tag: 'update-column',
          table,
          old: {name: oldName, spec: oldSpec},
          new: {name: newName, spec: newSpec},
        });
      }
    }

    // ADD
    for (const id of added) {
      const {name, ...spec} = must(newColumns.get(id));
      const column = {name, spec};
      try {
        // Validate that the ChangeProcessor will accept the column change.
        mapPostgresToLiteColumn(table.name, column);
      } catch (cause) {
        throw new UnsupportedSchemaChangeError({cause});
      }
      changes.push({tag: 'add-column', table, column});
    }
    return changes;
  }

  #parseReplicationEvent(content: Uint8Array) {
    const str =
      content instanceof Buffer
        ? content.toString('utf-8')
        : new TextDecoder().decode(content);
    const json = JSON.parse(str);
    return v.parse(json, replicationEventSchema, 'passthrough');
  }

  /**
   * If `ddlDetection === true`, relation messages are irrelevant,
   * as schema changes are detected by event triggers that
   * emit custom messages.
   *
   * For degraded-mode replication (`ddlDetection === false`):
   * 1. query the current published schemas on upstream
   * 2. compare that with the InternalShardConfig.initialSchema
   * 3. compare that with the incoming MessageRelation
   * 4. On any discrepancy, throw an UnsupportedSchemaChangeError
   *    to halt replication.
   *
   * Note that schemas queried in step [1] will be *post-transaction*
   * schemas, which are not necessarily suitable for actually processing
   * the statements in the transaction being replicated. In other words,
   * this mechanism cannot be used to reliably *replicate* schema changes.
   * However, they serve the purpose determining if schemas have changed.
   */
  async #handleRelation(rel: MessageRelation): Promise<ChangeStreamData[]> {
    const {publications, ddlDetection} = this.#shardConfig;
    if (ddlDetection) {
      return [];
    }
    const currentSchema = await getPublicationInfo(
      this.#upstream.db,
      publications,
    );
    if (schemasDifferent(this.#initialSchema, currentSchema, this.#lc)) {
      throw new UnsupportedSchemaChangeError();
    }
    // Even if the currentSchema is equal to the initialSchema, the
    // MessageRelation itself must be checked to detect transient
    // schema changes within the transaction (e.g. adding and dropping
    // a table, or renaming a column and then renaming it back).
    const orel = this.#initialSchema.tables.find(
      t => t.oid === rel.relationOid,
    );
    if (!orel) {
      // Can happen if a table is created and then dropped in the same transaction.
      this.#lc.info?.(`relation not in initialSchema: ${stringify(rel)}`);
      throw new UnsupportedSchemaChangeError();
    }
    if (relationDifferent(orel, rel)) {
      this.#lc.info?.(
        `relation has changed within the transaction: ${stringify(orel)}`,
        rel,
      );
      throw new UnsupportedSchemaChangeError();
    }
    return [];
  }
}

export function schemasDifferent(
  a: PublishedSchema,
  b: PublishedSchema,
  lc?: LogContext,
) {
  // Note: ignore indexes since changes need not to halt replication
  return (
    a.tables.length !== b.tables.length ||
    a.tables.some((at, i) => {
      const bt = b.tables[i];
      if (tablesDifferent(at, bt)) {
        lc?.info?.(`table ${stringify(at)} has changed`, bt);
        return true;
      }
      return false;
    })
  );
}

// ColumnSpec comparator
const byColumnPos = (a: [string, ColumnSpec], b: [string, ColumnSpec]) =>
  a[1].pos < b[1].pos ? -1 : a[1].pos > b[1].pos ? 1 : 0;

export function tablesDifferent(a: PublishedTableSpec, b: PublishedTableSpec) {
  if (
    a.oid !== b.oid ||
    a.schema !== b.schema ||
    a.name !== b.name ||
    !deepEqual(a.primaryKey, b.primaryKey)
  ) {
    return true;
  }
  const acols = Object.entries(a.columns).sort(byColumnPos);
  const bcols = Object.entries(b.columns).sort(byColumnPos);
  return (
    acols.length !== bcols.length ||
    acols.some(([aname, acol], i) => {
      const [bname, bcol] = bcols[i];
      return (
        aname !== bname ||
        acol.pos !== bcol.pos ||
        acol.typeOID !== bcol.typeOID ||
        acol.notNull !== bcol.notNull
      );
    })
  );
}

export function relationDifferent(a: PublishedTableSpec, b: MessageRelation) {
  if (
    a.oid !== b.relationOid ||
    a.schema !== b.schema ||
    a.name !== b.name ||
    // The MessageRelation's `keyColumns` field contains the columns in column
    // declaration order, whereas the PublishedTableSpec's `primaryKey`
    // contains the columns in primary key (i.e. index) order. Do an
    // order-agnostic compare here since it is not possible to detect
    // key-order changes from the MessageRelation message alone.
    !equals(new Set(a.primaryKey), new Set(b.keyColumns))
  ) {
    return true;
  }
  const acols = Object.entries(a.columns).sort(byColumnPos);
  const bcols = b.columns;
  return (
    acols.length !== bcols.length ||
    acols.some(([aname, acol], i) => {
      const bcol = bcols[i];
      return aname !== bcol.name || acol.typeOID !== bcol.typeOid;
    })
  );
}

function translateError(e: unknown): Error {
  if (!(e instanceof Error)) {
    return new Error(String(e));
  }
  if (e instanceof postgres.PostgresError && e.code === PG_ADMIN_SHUTDOWN) {
    return new ShutdownSignal(e);
  }
  return e;
}
const idString = (id: Identifier) => `${id.schema}.${id.name}`;

function specsByID(published: PublishedSchema) {
  return [
    // It would have been nice to use a CustomKeyMap here, but we rely on set-utils
    // operations which use plain Sets.
    new Map(published.tables.map(t => [t.oid, t])),
    new Map(published.indexes.map(i => [idString(i), i])),
  ] as const;
}

function columnsByID(
  columns: Record<string, ColumnSpec>,
): Map<number, ColumnSpec & {name: string}> {
  const colsByID = new Map<number, ColumnSpec & {name: string}>();
  for (const [name, spec] of Object.entries(columns)) {
    // The `pos` field is the `attnum` in `pg_attribute`, which is a stable
    // identifier for the column in this table (i.e. never reused).
    colsByID.set(spec.pos, {...spec, name});
  }
  return colsByID;
}

export class UnsupportedSchemaChangeError extends Error {
  readonly name = 'UnsupportedSchemaChangeError';

  constructor(options?: ErrorOptions) {
    super(
      'Replication halted. Schema changes cannot be reliably replicated without event trigger support. Resync the replica to recover.',
      options,
    );
  }
}

class ShutdownSignal extends AbortError {
  readonly name = 'ShutdownSignal';

  constructor(cause: unknown) {
    super(
      'shutdown signal received (e.g. another zero-cache taking over the replication stream)',
      {
        cause,
      },
    );
  }
}
